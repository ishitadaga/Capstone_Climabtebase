{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfreader\n",
    "from pdfreader import PDFDocument, SimplePDFViewer\n",
    "import os\n",
    "# import fitz \n",
    "import pdfplumber\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/ishitadaga/Downloads/Capstone Climabtebase/Aratina Solar DEIR Vol 1 Chapters 1-10.pdf\"\n",
    "# from io import BytesIO\n",
    "# with open(\"/Users/ishitadaga/Downloads/Capstone Climabtebase/Aratina Solar DEIR Vol 1 Chapters 1-10.pdf\", \"rb\") as f:\n",
    "#     stream = BytesIO(f.read())\n",
    "# doc2 = PDFDocument(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def extract_sections_from_pdf(pdf_path, start_page, end_page):\n",
    "    # Open the PDF file\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        # Create a PDF reader object\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        all_sections = []\n",
    "        # Initialize an empty string to store the extracted text\n",
    "        extracted_text = \"\"\n",
    "        \n",
    "        # Iterate through each page of the PDF\n",
    "        for page_num in range(start_page - 1, end_page):\n",
    "            # Get the page object\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            \n",
    "            # Extract text from the page\n",
    "            page_text = page.extract_text()\n",
    "\n",
    "            \n",
    "            lines = page_text.split('\\n')\n",
    "            for line in lines:\n",
    "                if line.strip():\n",
    "                    if \"greenhouse\" in line.lower():\n",
    "                        section = (line.split())[1]\n",
    "\n",
    "            # all_sections.extend(sections)\n",
    "            # Append the extracted text to the overall extracted_text\n",
    "            extracted_text = page_text\n",
    "        # print(all_sections)\n",
    "        # Return the extracted text\n",
    "        return extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"/Users/ishitadaga/Downloads/Capstone Climabtebase/Aratina Solar DEIR Vol 1 Chapters 1-10.pdf\"\n",
    "start_page = 30  # Start page number\n",
    "end_page = 37 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Section', '4.8', 'Greenhouse', 'Gas', 'Emissions', '................................', '................................', '..', '4.8-1']\n"
     ]
    }
   ],
   "source": [
    "extracted_text = extract_sections_from_pdf(pdf_path, start_page, end_page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPA 6; ZC 6, CUP 16, CUP 17 Map 192  \n",
      "WO #PP20401 (EIR - Aratina Solar  2.0) \n",
      "I:\\Planning \\WORKGRPS \\WP\\LABELS \\\n",
      "EIR05 -19JJ.nop.doc  \n",
      "Sc  07/29/20   City of Arvin  \n",
      "P.O. Box 548  \n",
      "Arvin, CA  93203   Bakersfield City Planning Dept  \n",
      "1715 Ches ter Avenue  \n",
      "Bakersfield, CA 93301  \n",
      "Bakersfield City Public Works Dept  \n",
      "1501 Truxtun Avenue  \n",
      "Bakersfield, CA 93301   California City Planning Dept  \n",
      "21000 Hacienda Blvd.  \n",
      "California City, CA 93515   Delano City Planning Dept  \n",
      "P.O. Box 3010  \n",
      "Delano, CA  93216  \n",
      "City o f Maricopa  \n",
      "P.O. Box 548  \n",
      "Maricopa, CA  93252   City of McFarland  \n",
      "401 West Kern Avenue  \n",
      "McFarland, CA  93250   City of Ridgecrest  \n",
      "100 West California Avenue  \n",
      "Ridgecrest, CA 93555  \n",
      "City of Shafter  \n",
      "336 Pacific Avenue  \n",
      "Shafter, CA  93263   City of Taft  \n",
      "Planning & Bui lding  \n",
      "209 E ast Kern Street  \n",
      "Taft, CA  93268   City of Tehachapi  \n",
      "Attn:  John Schlosser  \n",
      "115 South Robinson Street  \n",
      "Tehachapi, CA  93561 -1722  \n",
      "City of Wasco  \n",
      "764 E Street  \n",
      "Wasco, CA  93280   Inyo County Planning Dept  \n",
      "P.O. Drawer \"L\"  \n",
      "Independence, CA  93526   Kings C ounty Plann ing Agency  \n",
      "1400 West Lacey Blvd, Bldg 6  \n",
      "Hanford, CA  93230  \n",
      "Los Angeles Co Reg Planning Dept  \n",
      "320 West Temple Street  \n",
      "Los Angeles, CA  90012   San Bernardino Co Planning Dept  \n",
      "385 North Arrowhead Avenue, 1st Floor  \n",
      "San Bernardino, CA  92415 -0182   San Luis Obisp o Co Planning Dept  \n",
      "Planning and Building  \n",
      "976 Osos Street  \n",
      "San Luis Obispo, CA  93408  \n",
      "Santa Barbara Co Resource Mgt Dept  \n",
      "123 East Anapamu Street  \n",
      "Santa Barbara, CA  93101   Tulare County Planning & Dev Dept  \n",
      "5961 South Mooney Boulevard  \n",
      "Visalia, CA  93291   Vent ura County RMA Planning Div  \n",
      "800 South Victoria Avenue, L1740  \n",
      "Ventura, CA  93009 -1740  \n",
      "U.S. Bureau of Land Management  \n",
      "Ridgecrest Field Office  \n",
      "300 South Richmond Road  \n",
      "Ridgecrest, CA  93555   China Lake Naval Weapons Center  \n",
      "Comm Plans  & Liaison  \n",
      "429 E Bowen, Building 981  \n",
      "Mail Stop 4001  \n",
      "China Lake, CA  93555   Edwards AFB, Mission Sustainability \n",
      "Liaison  \n",
      "412 TW, Bldg 2750, Ste 117 -14 \n",
      "195 East Popson Avenue  \n",
      "Edwards AFB, CA 93524  \n",
      "Federal Aviation Administration  \n",
      "Western Reg Office/  \n",
      "777 South  Aviation B oulevard \n",
      "Suite 150  \n",
      "El Segundo, CA 90245   Federal Communications Comm  \n",
      "18000 Studebaker Road, #660  \n",
      "Cerritos, CA  90701   U.S. Fish & Wildlife Service  \n",
      "777 East Tahquitz Canyon Way, Suite 208  \n",
      "Palm Springs, CA  92262  \n",
      "Eastern Kern Resource Cons Dist  \n",
      "300 South Ri chmo nd Road  \n",
      "Ridgecrest, CA  93555 -4436   Environmental Protection Agency  \n",
      "Region IX Office  \n",
      "75 Hawthorn Street  \n",
      "San Francisco, CA  94105   U.S. Dept of Agriculture/NRCS  \n",
      "5080 California Avenue, Ste 150  \n",
      "Bakersfield, CA 93309 -0711  \n"
     ]
    }
   ],
   "source": [
    "print(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PDFSegmenter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-72b052f8e62d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mPDFSegmenter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msegmenter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPDFSegmenter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'PDFSegmenter'"
     ]
    }
   ],
   "source": [
    "import PDFSegmenter\n",
    "segmenter = PDFSegmenter(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "from pdfminer.high_level import extract_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-59b08a146cef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0mflag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_sections_end\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                     \u001b[0msection_complete\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0mflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/booksum/venv/lib/python3.9/site-packages/pdfplumber/page.py\u001b[0m in \u001b[0;36mextract_words\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextract_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT_obj_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     def extract_text_lines(\n",
      "\u001b[0;32m~/Downloads/booksum/venv/lib/python3.9/site-packages/pdfplumber/utils/text.py\u001b[0m in \u001b[0;36mextract_words\u001b[0;34m(chars, **kwargs)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT_obj_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT_obj_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mWordExtractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/booksum/venv/lib/python3.9/site-packages/pdfplumber/utils/text.py\u001b[0m in \u001b[0;36mextract_words\u001b[0;34m(self, chars)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextract_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchars\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT_obj_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT_obj_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_chars\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_extract_tuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/booksum/venv/lib/python3.9/site-packages/pdfplumber/utils/text.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextract_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchars\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT_obj_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT_obj_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_chars\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_extract_tuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/booksum/venv/lib/python3.9/site-packages/pdfplumber/utils/text.py\u001b[0m in \u001b[0;36miter_extract_tuples\u001b[0;34m(self, chars)\u001b[0m\n\u001b[1;32m    674\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_chars_to_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             )\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline_chars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mword_chars\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_chars_to_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_chars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_chars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_chars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_chars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/booksum/venv/lib/python3.9/site-packages/pdfplumber/utils/text.py\u001b[0m in \u001b[0;36miter_chars_to_lines\u001b[0;34m(self, chars)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0;31m# Cluster by line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m         subclusters = cluster_objects(\n\u001b[0m\u001b[1;32m    654\u001b[0m             \u001b[0mchars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0mline_cluster_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/booksum/venv/lib/python3.9/site-packages/pdfplumber/utils/clustering.py\u001b[0m in \u001b[0;36mcluster_objects\u001b[0;34m(xs, key_fn, tolerance, preserve_order)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mgrouped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_tuples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/booksum/venv/lib/python3.9/site-packages/pdfplumber/utils/clustering.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mgrouped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_tuples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "flag = 0\n",
    "with pdfplumber.open(path) as pdf:\n",
    "    \n",
    "    for page in pdf.pages:\n",
    "        text = page.extract_text()\n",
    "        if \"table of contents\" in text.lower():\n",
    "            if \"greenhouse gas emissions\" in text.lower():\n",
    "                section = [i.split()[1] for i in page.extract_text_simple().split(\"\\n\") if \"greenhouse gas emission\" in i.lower()][0]\n",
    "                ghg_section_start = [i.split()[-1] for i in page.extract_text_simple().split(\"\\n\") if \"greenhouse gas emission\" in i.lower()][0]\n",
    "                ghg_sections_end = str(round(float(section)+float(0.1),2)) + \"-1\"\n",
    "                flag+=1 \n",
    "                print(flag)\n",
    "\n",
    "            if \"agriculture and forestry resources\" in text.lower():\n",
    "                section = [i.split()[1] for i in page.extract_text_simple().split(\"\\n\") if \"agriculture and forestry resources\" in i.lower()][0]\n",
    "                ag_section_start = [i.split()[-1] for i in page.extract_text_simple().split(\"\\n\") if \"agriculture and forestry resources\" in i.lower()][0]\n",
    "                ag_sections_end = str(round(float(section)+float(0.1),2)) + \"-1\"\n",
    "                flag+=1 \n",
    "                print(flag)\n",
    "\n",
    "            if \"biological resources\" in text.lower():\n",
    "                section = [i.split()[1] for i in page.extract_text_simple().split(\"\\n\") if \"biological resources\" in i.lower()][0]\n",
    "                br_section_start = [i.split()[-1] for i in page.extract_text_simple().split(\"\\n\") if \"biological resources\" in i.lower()][0]\n",
    "                br_sections_end = str(round(float(section)+float(0.1),2)) + \"-1\"\n",
    "                flag+=1 \n",
    "                print(flag)\n",
    "\n",
    "        if flag==3:\n",
    "            break;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12800"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import anthropic\n",
    "\n",
    "client = anthropic.Anthropic(\n",
    "    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "    api_key=\"my_api_key\",\n",
    ")\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-opus-20240229\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0.0,\n",
    "    system=\"Respond only in Yoda-speak.\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"How are you today?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "import os\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"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\"\n",
    "client = anthropic.Anthropic()\n",
    "# print(os.environ.get(\"ANTHROPIC_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.messages.create(\n",
    "    model=\"claude-3-sonnet-20240229\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0.0,\n",
    "    system=\"Using the below environment impact report for a Solar project, respond to the question like a policy expert.\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"Question:\\nSummarise the biological impact of this solar project.\\n\\nContext:\\n{biological_resource}\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the key points regarding biological resource impacts and mitigation measures for the Aratina Solar Project:\n",
      "\n",
      "Special-Status Species Impacts:\n",
      "- Potential impacts to special-status plants like desert cymopterus, Barstow woolly sunflower, Mojave spineflower, crowned muilla, and western Joshua tree from habitat loss and removal. Mitigated to less than significant with MM 4.4-1 through MM 4.4-13.\n",
      "\n",
      "- Potential impacts to Mohave ground squirrel, desert tortoise, burrowing owl, desert kit fox, American badger, raptors like golden eagle, and migratory birds from habitat loss, vehicle strikes, noise/human disturbance. Mitigated to less than significant with MM 4.4-1 through MM 4.4-11, MM 4.4-14 through MM 4.4-22.\n",
      "\n",
      "- Potential increase in common raven populations, which prey on other species. Mitigated to less than significant with MM 4.4-22 (Raven Management Plan).\n",
      "\n",
      "Sensitive Natural Communities:\n",
      "- Impacts to sensitive natural communities like spinescale scrub and Joshua tree woodland from vegetation removal. Mitigated to less than significant with MM 4.4-14.\n",
      "\n",
      "Jurisdictional Waters: \n",
      "- No impacts to federal waters, but impacts to state waters (ephemeral drainages) requiring permits/mitigation. Mitigated to less than significant with MM 4.4-23 through MM 4.4-25.\n",
      "\n",
      "Wildlife Movement:\n",
      "- Less than significant impacts to wildlife movement with MM 4.1-4 through MM 4.1-6 (lighting), MM 4.4-1 through MM 4.4-11, MM 4.4-20, MM 4.4-22.\n",
      "\n",
      "Cumulative Impacts:\n",
      "- Significant and unavoidable cumulative impacts due to loss of habitat for special-status/transient species like desert tortoise, despite mitigation.\n",
      "\n",
      "The key mitigation approach involves pre-construction surveys, worker training, biological monitoring, habitat compensation/restoration, raven management, and measures to protect species during construction like exclusion fencing.\n"
     ]
    }
   ],
   "source": [
    "#br\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a summary of the agriculture impact from this solar project:\n",
      "\n",
      "- The project site does not contain any Prime Farmland, Unique Farmland, or Farmland of Statewide Importance as mapped by the California Department of Conservation. It is designated as Nonagricultural or Natural Vegetation land.\n",
      "\n",
      "- The site is zoned A-1 Limited Agriculture, M-1 Light Industrial, and R-1 Low-Density Residential. The project proposes to rezone it to A Exclusive Agriculture, which allows solar projects with a conditional use permit. So it would not conflict with agricultural zoning.\n",
      "\n",
      "- There are no Williamson Act contract lands on or adjacent to the site, so the project would not conflict with Williamson Act contracts.\n",
      "\n",
      "- The site is located in an area with limited potential for future farming activities due to groundwater basin adjudication and rampdown of allowable groundwater production. \n",
      "\n",
      "- While the project would convert land zoned for agriculture to a solar use, it would not result in loss of productive farmland since the site has never been used for agriculture.\n",
      "\n",
      "In summary, while the project site is zoned for agriculture, it does not actually contain productive farmland and has limited potential for future agricultural use due to water constraints. Rezoning to allow the solar project would not conflict with agricultural zoning or Williamson Act contracts. So the agricultural impact is considered less than significant.\n"
     ]
    }
   ],
   "source": [
    "#ag\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the key points regarding greenhouse gas emissions and climate change impacts from the proposed Aratina Solar Project:\n",
      "\n",
      "- Construction and decommissioning of the project would generate an estimated 8,578 MTCO2e over a 15-month construction period. Amortized over the 30-year project lifetime, this amounts to 572 MTCO2e per year.\n",
      "\n",
      "- Annual operational emissions are estimated at 257 MTCO2e per year, primarily from worker commutes. Adding the amortized construction emissions, total annual emissions would be 829 MTCO2e.\n",
      "\n",
      "- However, the project's generation of 530 MW of renewable solar electricity is estimated to displace 318,611 MTCO2e per year from fossil fuel-based power generation. \n",
      "\n",
      "- Therefore, the net annual GHG emissions impact would be a reduction of 317,782 MTCO2e per year.\n",
      "\n",
      "- The project would be consistent with California's Climate Change Scoping Plan, Renewables Portfolio Standard, and other GHG reduction plans and policies by providing renewable energy generation.\n",
      "\n",
      "- The project's GHG emissions would fall below regional regulatory thresholds set by the Eastern Kern Air Pollution Control District.\n",
      "\n",
      "- Cumulatively, the project and other renewable energy projects are essential to achieving California's renewable energy and GHG reduction goals under AB 32, SB 32 and SB 100.\n",
      "\n",
      "In summary, while the project would generate some GHG emissions during construction and operation, it would result in a substantial net reduction in GHG emissions by displacing fossil fuel-based electricity generation. The impact analysis concludes the project's GHG emissions impacts would be less than significant.\n"
     ]
    }
   ],
   "source": [
    "#ghg\n",
    "print(\"\"\"Here are the key points regarding greenhouse gas emissions and climate change impacts from the proposed Aratina Solar Project:\\n\\n- Construction and decommissioning of the project would generate an estimated 8,578 MTCO2e over a 15-month construction period. Amortized over the 30-year project lifetime, this amounts to 572 MTCO2e per year.\\n\\n- Annual operational emissions are estimated at 257 MTCO2e per year, primarily from worker commutes. Adding the amortized construction emissions, total annual emissions would be 829 MTCO2e.\\n\\n- However, the project's generation of 530 MW of renewable solar electricity is estimated to displace 318,611 MTCO2e per year from fossil fuel-based power generation. \\n\\n- Therefore, the net annual GHG emissions impact would be a reduction of 317,782 MTCO2e per year.\\n\\n- The project would be consistent with California's Climate Change Scoping Plan, Renewables Portfolio Standard, and other GHG reduction plans and policies by providing renewable energy generation.\\n\\n- The project's GHG emissions would fall below regional regulatory thresholds set by the Eastern Kern Air Pollution Control District.\\n\\n- Cumulatively, the project and other renewable energy projects are essential to achieving California's renewable energy and GHG reduction goals under AB 32, SB 32 and SB 100.\\n\\nIn summary, while the project would generate some GHG emissions during construction and operation, it would result in a substantial net reduction in GHG emissions by displacing fossil fuel-based electricity generation. The impact analysis concludes the project's GHG emissions impacts would be less than significant.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ishitadaga/Downloads/booksum/venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from /Users/ishitadaga/Downloads/Capstone Climabtebase/mistral-7b-instruct-v0.2.Q5_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 17\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q5_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.78 GiB (5.67 BPW) \n",
      "llm_load_print_meta: general.name     = mistralai_mistral-7b-instruct-v0.2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  4892.99 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 24480\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: freq_base  = 1000000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =  3060.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 3060.00 MiB, K (f16): 1530.00 MiB, V (f16): 1530.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =  1609.82 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '8', 'llama.context_length': '32768', 'llama.attention.head_count': '32', 'llama.rope.freq_base': '1000000.000000', 'llama.rope.dimension_count': '128', 'general.file_type': '17', 'llama.feed_forward_length': '14336', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': 'mistralai_mistral-7b-instruct-v0.2'}\n",
      "Guessed chat format: mistral-instruct\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"\"\n",
    "from llama_cpp import Llama\n",
    "\n",
    "# tokenizer_2 = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
    "\n",
    "# # # removed cude here:                                              \n",
    "# model_2 = AutoModelForCausalLM.from_pretrained(\"/Users/ishitadaga/Downloads/Capstone Climabtebase/mistral-7b-instruct-v0.2.Q5_K_M.gguf\",\n",
    "#                                                 device_map=\"auto\",\n",
    "#                                              trust_remote_code=False,\n",
    "#                                              model_type=\"mistral\",\n",
    "#                                              # revision=\"mistral-7b-instruct-v0.1.Q4_K_M.gguf\"\n",
    "#                                              )\n",
    "\n",
    "model = Llama(model_path=\"/Users/ishitadaga/Downloads/Capstone Climabtebase/mistral-7b-instruct-v0.2.Q5_K_M.gguf\",n_ctx=24465 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 24465 is out of bounds for axis 0 with size 24465",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-1d79ef671ce6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Run the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mecho\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/booksum/venv/lib/python3.9/site-packages/llama_cpp/llama.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1559\u001b[0m             \u001b[0mResponse\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgenerated\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1560\u001b[0m         \"\"\"\n\u001b[0;32m-> 1561\u001b[0;31m         return self.create_completion(\n\u001b[0m\u001b[1;32m   1562\u001b[0m             \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1563\u001b[0m             \u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/booksum/venv/lib/python3.9/site-packages/llama_cpp/llama.py\u001b[0m in \u001b[0;36mcreate_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1492\u001b[0m             \u001b[0mchunks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCreateCompletionStreamResponse\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompletion_or_chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1494\u001b[0;31m         \u001b[0mcompletion\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCompletion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompletion_or_chunks\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1495\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcompletion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/booksum/venv/lib/python3.9/site-packages/llama_cpp/llama.py\u001b[0m in \u001b[0;36m_create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \u001b[0mfinish_reason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"length\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0mmultibyte_fix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m         for token in self.generate(\n\u001b[0m\u001b[1;32m   1020\u001b[0m             \u001b[0mprompt_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/booksum/venv/lib/python3.9/site-packages/llama_cpp/llama.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, tokens, top_k, top_p, min_p, typical_p, temp, repeat_penalty, reset, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, penalize_nl, logits_processor, stopping_criteria, grammar)\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[0;31m# Eval and sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msample_idx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 token = self.sample(\n",
      "\u001b[0;32m~/Downloads/booksum/venv/lib/python3.9/site-packages/llama_cpp/llama.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_vocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_past\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_tokens\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;31m# Update n_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mn_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 24465 is out of bounds for axis 0 with size 24465"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"<s>[INST] <<SYS>>\n",
    "Using the below environment impact report for a Solar project, respond to the question like a policy expert.\n",
    "<</SYS>>\n",
    "f\"Question:\\Given the environmental impact report, what is the total annual green house gas emission of the project.\\n\\nContext:\\n{ghg}[/INST]\"\"\"\n",
    "\n",
    "# Model parameters\n",
    "max_tokens = 2\n",
    "\n",
    "# Run the model\n",
    "output = model(prompt, max_tokens=max_tokens, echo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This function will be deprecated in a future release and `unstructured` will simply use the DEFAULT_MODEL from `unstructured_inference.model.base` to set default model name\n"
     ]
    }
   ],
   "source": [
    "from unstructured.partition.auto import partition\n",
    "elements = partition(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
